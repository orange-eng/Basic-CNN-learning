# new topic
## 前言
* 该markdown文档里面包含了很多topic，主要用于开阔视野。
****

# 笔记汇总

## 目录



## 编程技巧

- 点云目标检测 Point Cloud
https://blog.csdn.net/weixin_40400177/article/details/103541083
大有从2D向3D发展的趋势，比如在opencv中就已经慢慢包含了3D点云的处理的相关模块，在数据方面点云的获取也是有多种渠道， 无论是源于CAD模型还是来自LiDAR传感器或RGBD相机的扫描点云，无处不在。 另外，大多数系统直接获取3D点云而不是拍摄图像并进行处理

- 异常检测 anomaly detection
所谓异常检测就是发现与大部分对象不同的对象，其实就是发现离群点。异常检测有时也称偏差检测。翻译为中文意思是异常侦测，异常侦测要做的就是：让机器可以知道我不知道这件事。异常对象是相对罕见的。下面来举一些常见的异常检测的应用

- 人脸活体检测 Face-Anti-Spoofing
假照片和真照片的区别：
将假脸照片与真脸照片转化生成频域图，对比发现假脸的高频信息分布比较单一，仅沿着水平和垂直方向延伸，而真脸的高频信息从图像的中心向外呈发散状。


- backdoor attack

译为后门攻击或者特洛伊攻击，它是对于神经网络的一种攻击方式，它能够通过操纵输入使模型出现错误识别。举个例子，在交通标志的识别任务中，一个stop的标志牌原本能够被神经网络正确识别为停止，但如果在stop的标志牌上贴上一朵花的图案，它可能会被模型错误识别为加速。

以图像分类任务为例说明backdoor attack的流程，我们把能够诱导模型出现误分类的图案、像素块(不仅仅只有这几种，后续会提到)称之为trigger(触发器)，我们把带有trigger的输入样本称为poisoning sample（染毒样本）, 把没有trigger的输入样本称为benign sample（良性样本） 。首先我们得生成trigger，然后从benign sample当中选取一部分给它们附加上trigger并修改它的label(有些方式不用修改）变成poisoning sample，然后将它们作为训练集进行模型的训练，经过训练后后门就成功嵌入到了模型当中。在测试的环节，没有trigger的样本会被模型正常的分类，而带有trigger的样本会被误分类到指定的类别当中

- 场景识别  scene recognition
分为静态场景识别和动态场景识别

- 从噪声样本中学习 learn from noisy labels
噪声样本中，可能会出现“标记不明确，”
